{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a6755bb4-0142-4b16-8a20-1cb29904d4ac","cell_type":"code","source":"# INSTALL & IMPORT:\n!pip install pandas \n!pip install scikit-learn\n!pip install seaborn\n!pip install matplotlib \n!pip install numpy\n\nimport os\nfrom IPython.display import FileLink\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.tree import DecisionTreeRegressor as dtr\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.ensemble import RandomForestRegressor as rfr\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector","metadata":{"trusted":true},"outputs":[],"execution_count":24},{"id":"2e63b264-1e4d-41bc-ab53-d2cf3d160bb5","cell_type":"code","source":"train_data = pd.read_csv(\"/home/jovyan/train.csv\", index_col=\"Id\")\ntest_data = pd.read_csv(\"/home/jovyan/test.csv\", index_col=\"Id\")","metadata":{"trusted":true},"outputs":[],"execution_count":66},{"id":"ae180082-5df7-43b7-9c36-46aa6f1e4bc0","cell_type":"markdown","source":"# DATA VARIABLE ANALYSIS\n\n##### Definitions of the variables and the nature of the dataframe.\n","metadata":{}},{"id":"f389db90-7c8a-4609-8fa2-631136748772","cell_type":"code","source":"train_data.tail()","metadata":{"trusted":true},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\nId                                                                      \n1456          60       RL         62.0     7917   Pave   NaN      Reg   \n1457          20       RL         85.0    13175   Pave   NaN      Reg   \n1458          70       RL         66.0     9042   Pave   NaN      Reg   \n1459          20       RL         68.0     9717   Pave   NaN      Reg   \n1460          20       RL         75.0     9937   Pave   NaN      Reg   \n\n     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\nId                                    ...                                      \n1456         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n1457         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n1458         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n1460         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n\n     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \nId                                                               \n1456       0      8    2007        WD         Normal     175000  \n1457       0      2    2010        WD         Normal     210000  \n1458    2500      5    2010        WD         Normal     266500  \n1459       0      4    2010        WD         Normal     142125  \n1460       0      6    2008        WD         Normal     147500  \n\n[5 rows x 80 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1456</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1460</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 80 columns</p>\n</div>"},"metadata":{}}],"execution_count":67},{"id":"eac7d380-3639-4a63-bebd-2be284d44b5e","cell_type":"code","source":"print(\"Variable types in the data:\")\nprint(train_data.dtypes)\nprint(\"\\n\")\nprint('The shape of the data:', train_data.shape)\nprint(\"\\n\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Variable types in the data:\nMSSubClass         int64\nMSZoning          object\nLotFrontage      float64\nLotArea            int64\nStreet            object\n                  ...   \nMoSold             int64\nYrSold             int64\nSaleType          object\nSaleCondition     object\nSalePrice          int64\nLength: 80, dtype: object\n\n\nThe shape of the data: (1460, 80)\n\n\n","output_type":"stream"}],"execution_count":68},{"id":"73f7877f-e206-427f-8b04-c2da61acd6cb","cell_type":"markdown","source":"\nThe data we have consists of 80 variables both categorical and numerical with 1460 rows, where one is the dependent variable and the rest of the vairables are explanatory. \nHowever, for the sake of efficiency and good ML practise, not all variables will be used. For this project, only columns that are numerical and categorical columns with cardinality that is less than 10 will be utilised for the sake of the preprocessing stage (one-hot encoding).   ","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"id":"58f8f9a4-92ed-4c6b-8e28-13d40d041dda","cell_type":"markdown","source":"# DATA CLEANING\n\n#### 1. Missing values:","metadata":{}},{"id":"df6053e5-934a-4726-9ea5-4dd656b59f32","cell_type":"code","source":"miss_value_cols = [col for col in train_data.columns if train_data[col].isnull().any()] #Fetching the names of any columns with missing entries.\nprint(\"These are the columns with missing values along with the number of missing values: \\n \\n\", miss_value_cols)     # Printing the names.\nprint(\"\\n\")\nmissing_value_cols = train_data.isnull().sum()  # Finding the number of missing entries from each column.\nmissing_value_cols = missing_value_cols[missing_value_cols > 0]\nprint(missing_value_cols)   # Printing the names and the statistics.","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"These are the columns with missing values along with the number of missing values: \n \n ['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n\n\nLotFrontage      259\nAlley           1369\nMasVnrType       872\nMasVnrArea         8\nBsmtQual          37\nBsmtCond          37\nBsmtExposure      38\nBsmtFinType1      37\nBsmtFinType2      38\nElectrical         1\nFireplaceQu      690\nGarageType        81\nGarageYrBlt       81\nGarageFinish      81\nGarageQual        81\nGarageCond        81\nPoolQC          1453\nFence           1179\nMiscFeature     1406\ndtype: int64\n","output_type":"stream"}],"execution_count":69},{"id":"1588fd87-9979-4fcd-8168-719397cf8bc5","cell_type":"markdown","source":"It appears there are alot of missing values present within the data.\n\n##### Strategy: \nFor this data, the plan is to first remove the rows with missing values in the dependent column. For the numerical columns, the average of each column will be imputed in the respective column where values are missing. For the categorical columns, after the preprocessing part, will be imputed with the most frequent value in the respective columns. The same will be done for the test data, except for removing the dependent column since it does not have that.","metadata":{}},{"id":"20a8b238-3b20-4b4e-a205-0fcefe6f04a2","cell_type":"markdown","source":"### 2. Preprocessing stage:","metadata":{}},{"id":"ac9dad03-1ab4-4308-aa8a-2deb727a3048","cell_type":"code","source":"train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = train_data['SalePrice']\ntrain_data.drop(['SalePrice'], axis=1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":70},{"id":"fd4b8d9f-9807-490d-b512-819e3358a4a4","cell_type":"code","source":"train_x, valid_x, train_y, valid_y = tts(train_data, y, train_size=0.8, test_size=0.2, random_state=0)\n\nnum_cols = [col for col in train_x.columns if train_x[col].dtype in ['float64', 'int64']]\ncat_cols = [col for col in train_x.columns if train_x[col].dtype == 'object' and train_x[col].nunique() < 10]  # Fixed the comparison of dtype and function call\n\nmy_cols = num_cols + cat_cols\nx_train = train_x[my_cols].copy()\nx_valid = valid_x[my_cols].copy()\nx_test  = test_data[my_cols].copy()\n\ncat_transformer = Pipeline(steps=[('Impute', SimpleImputer(strategy='most_frequent')),  # Fixed the missing bracket\n                                  ('OH', OneHotEncoder(handle_unknown='ignore'))])\n\ntransformer = ColumnTransformer(transformers=[('num', SimpleImputer(strategy='mean'), num_cols),\n                                              ('cat', cat_transformer, cat_cols)])\n\n############ ALTERNATIVELY (if we we chose all numerical and categorical columns, we would just write):\n# transformer = ColumnTransformer(transformers=[('num', SimpleImputer(strategy='mean'), dtypes_include = np.number),\n#                                             ('cat', cat_transformer, dtype_include = object]) \n#                   OR (using make_column_transformer) more straight forward, less configuration :\n# transformer = make_column_transformer(\n#               (SimpleImputer(strategy='mean'), make_column_selector(dtype_include = np.number)), for numerical columns.\n#               (cat_transformer, make_column_selector(dtype_include = object)),                 for categorical columns\n# )\n\n\ntransformer.fit(x_train)  # Fit only on training data\nx_train_transformed = transformer.transform(x_train)\nx_valid_transformed = transformer.transform(x_valid)\n\n# Convert transformed arrays back to DataFrame\n\nx_train_transformed = pd.DataFrame(x_train_transformed, columns=transformer.get_feature_names_out())\nx_valid_transformed = pd.DataFrame(x_valid_transformed, columns=transformer.get_feature_names_out())\n\n# FOR THE TEST DATA\nx_test_transformed = transformer.transform(x_test)\nx_test_transformed = pd.DataFrame(x_test_transformed, columns=transformer.get_feature_names_out())","metadata":{"trusted":true},"outputs":[],"execution_count":71},{"id":"bcbb7e19-cbae-4134-8d6f-795bc1d14bce","cell_type":"markdown","source":"# EXPLANATORY DATA ANALYSIS\n\n##### Exploring the relationships between the variables.","metadata":{}},{"id":"7153ff35-5e6a-4b8b-9b77-bd759d7b9ff7","cell_type":"code","source":"print(\"Variable types in the data:\")\nprint(x_train_transformed.dtypes)\nprint(\"\\n\")\nprint('The shape of the data:', x_train_transformed.shape)\nprint(\"\\n\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Variable types in the data:\nnum__MSSubClass               float64\nnum__LotFrontage              float64\nnum__LotArea                  float64\nnum__OverallQual              float64\nnum__OverallCond              float64\n                               ...   \ncat__SaleCondition_AdjLand    float64\ncat__SaleCondition_Alloca     float64\ncat__SaleCondition_Family     float64\ncat__SaleCondition_Normal     float64\ncat__SaleCondition_Partial    float64\nLength: 226, dtype: object\n\n\nThe shape of the data: (1168, 226)\n\n\n","output_type":"stream"}],"execution_count":72},{"id":"39f5ce76-c0be-459f-9228-db22418d18e6","cell_type":"markdown","source":"##### In this newly transformed data, we have 226 columns which make it hard to read plots such as heatmaps (It was plotted then excluded here), so the best action (in this project) is to omit the EDA stage with hopes (bad practice) that we will get great results from our validation phase.","metadata":{}},{"id":"193b9b8b-069f-4411-bdba-f05eb20fd639","cell_type":"markdown","source":"# MODEL SELECTION / VALIDATION ANALYSIS","metadata":{}},{"id":"e969bb14-f2cf-42c6-80b8-b150e3c5e8f1","cell_type":"markdown","source":"##### Here we are going to try various models and metrics to see which model is the best for predictions.","metadata":{}},{"id":"8b9bfc4e-e51b-4cef-a3b9-293d3b1c16af","cell_type":"code","source":"tree = dtr(random_state = 0)\ntree.fit(x_train_transformed, train_y)\ntree_predictions = tree.predict(x_valid_transformed)\nprint(\"The mean square error for this tree model is: \", mae(tree_predictions,valid_y))","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"The mean square error for this tree model is:  27147.86301369863\n","output_type":"stream"}],"execution_count":74},{"id":"21b9b5cf-2a3d-4f1e-a00d-7c8d8fe03094","cell_type":"code","source":"forest_1 = rfr(n_estimators=50, random_state=0)\nforest_2 = rfr(n_estimators=100, random_state=0)\nforest_3 = rfr(n_estimators=100, criterion='absolute_error', random_state=0)\nforest_4 = rfr(n_estimators=200, min_samples_split=20, random_state=0)\nforest_5 = rfr(n_estimators=100, max_depth=7, random_state=0)\n\nmodels = [forest_1, forest_2, forest_3, forest_4, forest_5]","metadata":{"trusted":true},"outputs":[],"execution_count":75},{"id":"29ae6858-fe6e-4ccf-a8a9-db68c6e2c5b2","cell_type":"code","source":"scores = [0,0,0,0,0]\ni = 0\nfor model in models:\n    model.fit(x_train_transformed, train_y)\n    forest_predictions = model.predict(x_valid_transformed)\n    scores[i] = mae(forest_predictions, valid_y)\n    i +=1\n    \nprint(\"For the random forest trees the mean square absolute values are:\")\nfor k in [1,2,3,4,5]:\n    print(\"Random Forest model \", k, \":\\t\", scores[k-1]) ","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"For the random forest trees the mean square absolute values are:\nRandom Forest model  1 :\t 17809.410684931507\nRandom Forest model  2 :\t 17612.84342465753\nRandom Forest model  3 :\t 17853.850325342464\nRandom Forest model  4 :\t 18130.819020208157\nRandom Forest model  5 :\t 18299.191403133722\n","output_type":"stream"}],"execution_count":78},{"id":"02d56bd0-8600-47a3-a777-461e84163c72","cell_type":"markdown","source":"#### It is clear that the best model for the data is model 2 which gives the lowest mae value out of all the models.","metadata":{}},{"id":"13847a56-445c-47d7-994a-da823f12c1e5","cell_type":"code","source":"# Make predictions on the test data\ntest_preds = forest_2.predict(x_test_transformed)\n\n# Save the predictions in the format required for submission\noutput = pd.DataFrame({'Id': x_test_transformed.index, 'SalePrice': test_preds})\n\n# Define the file path for the submission\noutput_path = \"sample_submission.csv\"\n\n# Save the predictions to CSV\noutput.to_csv(output_path, index=False)\n\n# Create a clickable link for the file\ndisplay(FileLink(output_path))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}